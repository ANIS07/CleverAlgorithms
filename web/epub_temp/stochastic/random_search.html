<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <meta http-equiv="Content-Type" content="application/xhtml+xml; charset=utf-8" />
    <title>Clever Algorithms</title>
    <link rel="stylesheet" href="main.css" type="text/css" />
  </head>
  <body>
    
<a id='random_search'><h1>Random Search</h1></a>
<p>
<em>Random Search, RS, Blind Random Search, Blind Search, Pure Random Search, PRS</em>
</p>

<a id='taxonomy'><h2>Taxonomy</h2></a>
<p>
Random search belongs to the fields of Stochastic Optimization and Global Optimization.
Random search is a direct search method as it does not require derivatives to search a continuous domain.
This base approach is related to techniques that provide small improvements such as Directed Random Search, and Adaptive Random Search.
</p>


<a id='strategy'><h2>Strategy</h2></a>
<p>
The strategy of Random Search is to sample solutions from across the entire search space using a uniform probability distribution. Each future sample is independent of the samples that come before it.
</p>


<a id='procedure'><h2>Procedure</h2></a>
<p>
Algorithm (below) provides a pseudocode listing of the Random Search Algorithm for minimizing a cost function.
</p>
<div class='pseudocode'>
<strong><strong><code>Input</code></strong></strong>: 
<code>NumIterations</code>, <code>ProblemSize</code>, <code>SearchSpace</code>
<br />
<strong><strong><code>Output</code></strong></strong>: 
<code>Best</code>
<br />
<code>Best</code> $\leftarrow \emptyset$<br />
<strong><code>For</code></strong> ($iter_i \in$ <code>NumIterations</code>)<br />
&nbsp;&nbsp;&nbsp;&nbsp;$candidate_i$ $\leftarrow$ <code>RandomSolution</code>(<code>ProblemSize</code>, <code>SearchSpace</code>)<br />
&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>If</code></strong> (<code>Cost</code>($candidate_i$) &lt; <code>Cost</code>(<code>Best</code>))<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>Best</code> $\leftarrow$ $candidate_i$<br />
&nbsp;&nbsp;&nbsp;&nbsp;<strong><code>End</code></strong><br />
<strong><code>End</code></strong><br />
<strong><code>Return</code></strong> (<code>Best</code>)<br />
</div>
<div class='caption'>Pseudocode for Random Search.</div>



<a id='heuristics'><h2>Heuristics</h2></a>
<ul>
<li> Random search is minimal in that it only requires a candidate solution construction routine and a candidate solution evaluation routine, both of which may be calibrated using the approach.</li>
<li> The worst case performance for Random Search for locating the optima is worse than an Enumeration of the search domain, given that Random Search has no memory and can blindly resample.</li>
<li> Random Search can return a reasonable approximation of the optimal solution within a reasonable time under low problem dimensionality, although the approach does not scale well with problem size (such as the number of dimensions).</li>
<li> Care must be taken with some problem domains to ensure that random candidate solution construction is  unbiased</li>
<li> The results of a Random Search can be used to seed another search technique, like a local search technique (such as the Hill Climbing algorithm) that can be used to locate the best solution in the neighborhood of the 'good' candidate solution.</li>
</ul>


<a id='code_listing'><h2>Code Listing</h2></a>
<p>
Listing (below) provides an example of the Random Search Algorithm implemented in the Ruby Programming Language.
In the example, the algorithm runs for a fixed number of iterations and returns the best candidate solution discovered.
The example problem is an instance of a continuous function optimization that seeks $\min f(x)$ where $f=\sum_{i=1}^n x_{i}^2$, $-5.0\leq x_i \leq 5.0$ and $n=2$. The optimal solution for this basin function is $(v_0,\ldots,v_{n-1})=0.0$.
</p>
<pre class='prettyprint lang-rb'>
def objective_function(vector)
  return vector.inject(0) {|sum, x| sum + (x ** 2.0)}
end

def random_vector(minmax)
  return Array.new(minmax.size) do |i|
    minmax[i][0] + ((minmax[i][1] - minmax[i][0]) * rand())
  end
end

def search(search_space, max_iter)
  best = nil
  max_iter.times do |iter|
    candidate = {}
    candidate[:vector] = random_vector(search_space)
    candidate[:cost] = objective_function(candidate[:vector])
    best = candidate if best.nil? or candidate[:cost] &lt; best[:cost]
    puts " &gt; iteration=#{(iter+1)}, best=#{best[:cost]}"
  end
  return best
end

if __FILE__ == $0
  # problem configuration
  problem_size = 2
  search_space = Array.new(problem_size) {|i| [-5, +5]}
  # algorithm configuration
  max_iter = 100
  # execute the algorithm
  best = search(search_space, max_iter)
  puts "Done. Best Solution: c=#{best[:cost]}, v=#{best[:vector].inspect}"
end
</pre>
<div class='download_src'><a href='random_search.rb'>Download Source</a></div>
<div class='caption'>Random Search in Ruby</div>


<a id='references'><h2>References</h2></a>

<a id='primary_sources'><h3>Primary Sources</h3></a>
<p>
There is no seminal specification of the Random Search algorithm, rather there are discussions of the general approach and related random search methods from the 1950s through to the 1970s. This was around the time that pattern and direct search methods were actively researched.
Brooks is credited with the so-called 'pure random search'  [<a href='#Brooks1958'>Brooks1958</a>]. Two seminal reviews of 'random search methods' of the time include: Karnopp  [<a href='#Karnopp1963'>Karnopp1963</a>] and prhaps Kul'chitskii  [<a href='#Kulchitskii1976'>Kulchitskii1976</a>].
</p>


<a id='learn_more'><h3>Learn More</h3></a>
<p>
For overviews of Random Search Methods see Zhigljavsky  [<a href='#Zhigljavsky1991'>Zhigljavsky1991</a>], Solis and Wets  [<a href='#Solis1981'>Solis1981</a>], and also White  [<a href='#White1971'>White1971</a>] who provide an insightful review article.
Spall provides a detailed overview of the field of Stochastic Optimization, including the Random Search method  [<a href='#Spall2003'>Spall2003</a>] (for example, see Chapter 2). For a shorter introduction by Spall, see  [<a href='#Spall2004'>Spall2004</a>] (specifically Section 6.2). Also see Zabinsky for another detailed review of the broader field  [<a href='#Zabinsky2003'>Zabinsky2003</a>].
</p>




<h2>Bibliography</h2>
<table>
 <tr valign="top">
 <td><a id='Brooks1958'>[Brooks1958]</a></td>
 <td>S. H. Brooks, "<a href="http://scholar.google.com.au/scholar?q=A+Discussion+of+Random+Methods+for+Seeking+Maxima">A Discussion of Random Methods for Seeking Maxima</a>", Operations Research, 1958.</td>
 </tr>
 <tr valign="top">
 <td><a id='Karnopp1963'>[Karnopp1963]</a></td>
 <td>D. C. Karnopp, "<a href="http://scholar.google.com.au/scholar?q=Random+search+techniques+for+optimization+problems">Random search techniques for optimization problems</a>", Automatica, 1963.</td>
 </tr>
 <tr valign="top">
 <td><a id='Kulchitskii1976'>[Kulchitskii1976]</a></td>
 <td>O. Y. Kul'chitskii, "<a href="http://scholar.google.com.au/scholar?q=Random-search+algorithm+for+extrema+in+functional+space+under+conditions++of+partial+uncertainty">Random-search algorithm for extrema in functional space under conditions 	of partial uncertainty</a>", Cybernetics and Systems Analysis, 1976.</td>
 </tr>
 <tr valign="top">
 <td><a id='Solis1981'>[Solis1981]</a></td>
 <td>F. J. Solis and J. B. Wets, "<a href="http://scholar.google.com.au/scholar?q=Minimization+by+Random+Search+Techniques">Minimization by Random Search Techniques</a>", Mathematics of Operations Research, 1981.</td>
 </tr>
 <tr valign="top">
 <td><a id='Spall2003'>[Spall2003]</a></td>
 <td>J. C. Spall, "<a href="http://scholar.google.com.au/scholar?q=Introduction+to+stochastic+search+and+optimization:+estimation,+simulation,++and+control">Introduction to stochastic search and optimization: estimation, simulation, 	and control</a>", John Wiley and Sons, 2003.</td>
 </tr>
 <tr valign="top">
 <td><a id='Spall2004'>[Spall2004]</a></td>
 <td>J. C. Spall, "<a href="http://scholar.google.com.au/scholar?q=6.+Stochastic+Optimization">6. Stochastic Optimization</a>", in Handbook of computational statistics: concepts and methods, pages 169-198, Springer, 2004.</td>
 </tr>
 <tr valign="top">
 <td><a id='White1971'>[White1971]</a></td>
 <td>R. C. White, "<a href="http://scholar.google.com.au/scholar?q=A+survey+of+random+methods+for+parameter+optimization">A survey of random methods for parameter optimization</a>", Simulation, 1971.</td>
 </tr>
 <tr valign="top">
 <td><a id='Zabinsky2003'>[Zabinsky2003]</a></td>
 <td>Z. B. Zabinsky, "<a href="http://scholar.google.com.au/scholar?q=Stochastic+adaptive+search+for+global+optimization">Stochastic adaptive search for global optimization</a>", Kluwer Academic Publishers, 2003.</td>
 </tr>
 <tr valign="top">
 <td><a id='Zhigljavsky1991'>[Zhigljavsky1991]</a></td>
 <td>A. A. Zhigljavsky, "<a href="http://scholar.google.com.au/scholar?q=Theory+of+Global+Random+Search">Theory of Global Random Search</a>", Kluwer Academic, 1991.</td>
 </tr>
</table>


  </body>
</html>  

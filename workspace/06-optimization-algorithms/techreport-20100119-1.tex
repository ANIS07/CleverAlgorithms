% Unconventional Optimization Algorithms

% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2010 Jason Brownlee. All Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

\documentclass[a4paper, 11pt]{article}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{url}
\usepackage[pdftex,breaklinks=true,colorlinks=true,urlcolor=blue,linkcolor=blue,citecolor=blue,]{hyperref}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=25mm,bmargin=25mm,lmargin=25mm,rmargin=25mm}

% Dear template user: fill these in
\newcommand{\myreporttitle}{Unconventional Optimization Algorithms}
\newcommand{\myreportsubtitle}{An Overview}
\newcommand{\myreportauthor}{Jason Brownlee}
\newcommand{\myreportemail}{jasonb@CleverAlgorithms.com}
\newcommand{\myreportproject}{The Clever Algorithms Project\\\url{http://www.CleverAlgorithms.com}}
\newcommand{\myreportdate}{20100119}
\newcommand{\myreportversion}{1}
\newcommand{\myreportlicense}{\copyright\ Copyright 2010 Jason Brownlee. All Rights Reserved. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.}

% leave this alone, it's templated baby!
\title{{\myreporttitle}: {\myreportsubtitle}\footnote{\myreportlicense}}
\author{\myreportauthor\\{\myreportemail}\\\small\myreportproject}
\date{\today\\{\small{Technical Report: CA-TR-{\myreportdate}-\myreportversion}}}
\begin{document}
\maketitle

% write a summary sentence for each major section
\section*{Abstract} 
todo

\begin{description}
	\item[Keywords:] {\small\texttt{Clever, Algorithms, Unconventional, Optimization}}
\end{description} 

% summarise the document breakdown with cross references
\section{Introduction}
\label{sec:introduction}
% project
The Clever Algorithms project aims to describe a large number of Computational Intelligence and Natural Computation algorithms in a complete, consistent, and centralized manner \cite{Brownlee2010}.
% report
This report provides an overview of so-called `unconventional optimization algorithms'. These are stochastic global optimization algorithms drawn from the fields of Computational Intelligence, Biologically Inspired Computation, and Metaheurustics \cite{Brownlee2010c}.

% problems
Section~\ref{sec:problems} provides an overview of the general features that make computational problems difficult in the fields of Computational Intelligence and Metaheuristics and introduces two general classes of problem: function optimization and function approximation.
% unconventional optimization
Section~\ref{sec:unconventional_optimization} provides an introduction to unconventional optimization that introduces subjects such as black box methods, the `no free lunch theorem' of search and optimization, the importance of randomness in the broader field of stochastic optimization, an and general strategy of inductive learning. 
% conclusions
Finally, Section~\ref{sec:conclusions} relates the properties of unconventional global optimization to the approaches to be described in the Clever Algorithms project and highlights some ares for future consideration.

% 
%  Problems - based on copy from my thesis
% 
\section{Problems}
\label{sec:problems}
Algorithms from the fields of Computational Intelligence, Natural Computing, and Metaheuristics are applied to difficult problems, to which more traditional approaches may not be suited.
% problem types
Michalewicz and Fogel propose five reasons why problems may be difficult \cite{Michalewicz2004} (page 11):
\begin{itemize}
	\item The number of possible solutions in the search space is so large as to forbid an exhaustive search for the best answer.
	\item The problem is so complicated that just to facilitate any answer at all, we have to use such simplified models of the problem that any result is essentially useless.
	\item The evaluation function that describes the quality of any proposed solution is noisy or varies with time, thereby requiring not just a single solution but an entire series of solutions.
	\item The possible solutions that are so heavily constrained that constructing even one feasible answer is difficult, let alone searching for an optimal solution.
	\item The person solving the problem is inadequately prepared or imagines some psychological barrier that prevents them from discovering a solution.
\end{itemize}

% classes
This section introduces two problem formalisms that embody many of the most difficult problems faced by Artificial and Computational Intelligence. They are: Function Optimization (in Section~\ref{subsec:function_optimization}) and Function Approximation (in Section~\ref{subsec:function_approximation}). Each class of problem is described in terms of its general properties, a formalism, and a set of specialized sub-problems. These problem classes provide a tangible framing if algorithmic techniques drawn from the fields of Computational Intelligence, Natural Computing, and Metaheuristics.

% 
%  Function Optimization - based on copy from my thesis
%
\subsection{Function Optimization}
\label{subsec:function_optimization}
Real-world optimization problems and generalizations thereof can be drawn from most fields of science, engineering, and information technology (for a sample see \cite{Ali1997, Toern1999}). Importantly, optimization problems have had a long tradition in the fields of Artificial Intelligence and Computational Intelligence in motivating basic research into new problem solving techniques, and for investigating and verifying systemic behavior against benchmark problem instances.

%
% Problem Definition
%
\subsubsection{Problem Description}
% definition
Optimization (in the mathematical sense), is defined as the search for a combination of parameters commonly referred to as \emph{decision variables} ($x = \left\{x_1, x_2, x_3, \ldots x_n\right\}$) which minimize or maximize some ordinal quantity ($c$) (typically a scalar  called a score or cost) assigned by an \emph{objective function} or \emph{cost function} ($f$), under a set of constraints ($g = \left\{g_1, g_2, g_3, \ldots g_n\right\}$). For example, a general minimization case would be as follows: $f(x\prime) \leq f(x), \forall x_i \in x$. Constraints may provide boundaries on decision variables (for example in a real-value hypercube $\Re^n$), or may generally define regions of feasibility and in-feasibility in the decision variable space or cost space. In applied mathematics the field may be referred to as \emph{Mathematical Programming}. More generally the field may be referred to as \emph{Global} or \emph{Function Optimization} given the focus on the objective function (for more general information on optimization, see \cite{Horst2000}). 

%
% Sub-fields
%
\subsubsection{Sub-Fields of Study}
% general taxonomy
The study of optimization is comprised of many specialized sub-fields, generally based on an overlapping taxonomy that focuses on the principle concerns in the general formalism. 
% general fields
For example, with regard to the decision variables, one may consider univariate and multivariate optimization problems. The type of decision variables promotes the specialities for continuous, discrete, and permutations of variables. Dependencies between decision variables under a cost function defines the fields of Linear Programming, Quadratic Programming, and Nonlinear Programming. A large class of optimization problems can be reduced to discrete sets, which are considered in the field of Combinatorial Optimization, to which many theoretical properties are known, most importantly that many interesting and relevant problems cannot be solved by an approach with polynomial time complexity (so-called NP-complete, for example see \cite{Papadimitriou1998}).

% need for more complex models
The topography of the response surface for the decision variables under the cost function may be convex, which is an important class of functions to which many important theoretical findings have been made, not limited to the fact that location of the local optimal configuration also means the global optimal configuration of decisional variables has been located \cite{Boyd2004}. Many interesting and real-world optimization problems produce cost surfaces that are non-convex or so called multi-modal\footnote{Taken from statistics referring to the centers of mass in distributions, although in optimization it refers to `regions of interest' in the search space, in particular valleys in minimization, and peaks in maximization cost surfaces.} (rather than uni-modal) suggesting that there are multiple peaks and valleys. Further, many real-world optimization problems with continuous decision variables cannot be differentiated given their complexity or limited information availability meaning that derivative-based gradient decent methods that are well understood are not applicable, requiring the use of so-called `direct search' (sample or pattern-based) methods \cite{Lewis2000}. Further, real-world objective function evaluation may be noisy, non-continuous, and dynamic, and the constraints of real-world problem solving may require a viable or approximate solution in limited time or resources, motivating the need for inductive model-generation based approaches.


% 
%  Function Approximation - based on copy from my thesis
%
\subsection{Function Approximation}
\label{subsec:function_approximation}
% relation to ai and ci
The phrasing of real-world problems in the Function Approximation formalism are among the most computationally difficult considered in the broader field of Artificial Intelligence for reasons including: incomplete information, high-dimensionality, noise in the sample observations, and non-linearities in the target function.
% this section
This section considers the \emph{Function Approximation Formalism} and related specialization's as a general motivating problem for demonstrating the suitability of the applicability of clonal selection algorithms from across the hierarchical framework.

%
% Problem Definition
%
\subsubsection{Problem Description}
% definition
Function Approximation is an \emph{inductive problem} of finding a function ($f$) that approximates a target function ($g$), where typically the approximated function is selected based on a sample of observations ($x$, also referred to as the \emph{training set}) taken from the unknown target function.
% ML
In machine learning, the function approximation formalism is used to describe general problem types commonly referred to as \emph{pattern recognition}, such as classification, clustering, and curve fitting (so-called decision or discrimination function). Specifically, such general problem types are described in terms of approximating an unknown Probability Density Function (PDF), which underlies the relationships in the problem space, and represented to some degree in the sample data. This function approximation perspective of such problems is commonly referred to as \emph{statistical machine learning} and/or density estimation \cite{Fukunaga1990, Bishop1995}.

%
% Sub-Fields of Study
%
\subsubsection{Sub-Fields of Study}
% really hard
The function approximation formalism can be used to phrase some of the hardest problems faced by Computer Science, and Artificial Intelligence in particular such as natural language processing and computer vision. 
% general process
The general process focuses on (1) the collection and preparation of the observations from the target function, (2) the selection and/or preparation of a model of the target function, and (3) the application and ongoing refinement of the prepared model. 
% important problem types 
Some important problem-based sub-fields include: \emph{Feature Selection} where a feature is considered an aggregation of attributes, where only those features that have meaning in the context of the target function are necessary to the modeling process \cite{Kudo2000, Guyon2003}, \emph{Classification} where observations are inherently organized into labelled groups (classes) and a supervised process models an underlying discrimination function to classify unobserved samples, \emph{Clustering} where observations may be organized into inherent groups based on common features although the groups are unlabeled requiring a process to model an underlying discrimination function without corrective feedback, and \emph{Curve or Surface Fitting} where a model is prepared that provides a `best-fit' (or regression) for a set of observations that may be used for \emph{interpolation} over known observations and \emph{extrapolation} for observations outside what has been observed.

% optimisation
The field of Function Optimization is related to Function Approximation, as many-sub-problems of Function Approximation may be defined as optimization problems. As such many of the inductive modeling paradigms are differentiated based on the representation used and/or the optimization process used to minimize error or maximize effectiveness on a given approximation problem. 
% problems
The difficulty of Function Approximation problems centre around (i) the nature of the unknown relationships between attributes and features, (ii) the number (dimensionality) of of attributes and features, and (iii) general concerns of noise in such relationships and the dynamic availability of samples from the target function.
% other problems
Additional difficulties include the incorporation of prior knowledge (such as imbalance in samples, incomplete information and the variable reliability of data), and problems of invariant features (such as transformation, translation, rotation, scaling and skewing of features).


% 
% Unconventional Optimization
% 
\section{Unconventional Optimization}
\label{sec:unconventional_optimization}
% context
This selection provides an overview of so-named \emph{unconventional algorithms} for the function optimization class of problem. These types of algorithms comprise the majority of approaches selected for description in the Clever Algorithms project drawn from the fields of Computational Intelligence, Natural Computation, and Metaheuristics \cite{Brownlee2010b}. 
% unconventional
These algorithms are referred to as `unconventional' to differentiate them from the more traditional approaches, not limited to mathematical optimization algorithms (such as Newton's method and Gradient descent that uses derivatives to locate a local minimum) and the later direct search methods (such as the Simplex method and the Nelder-Mead method that use a search pattern to locate optima).

% section
Unconventional optimization algorithms are designed for the more difficult problem instances, the attributes of which were introduced in Section~\ref{subsec:function_optimization}. This section introduces some common attributes of this class of algorithm including: black box methods (Section~\ref{subsec:black_box}), the no-free-lunch theorem (Section~\ref{subsec:nfl}), the broader field of stochastic optimization (Section~\ref{subsec:stochastic}), and general approach of inductive learning (Section~\ref{subsec:induction}).

% 
% Black Box Methods
% 
\subsection{Black Box Algorithms}
\label{subsec:black_box}
% overview
Black Box optimization algorithms are those that exploit little, if any, information from a problem domain in devising a solution. They are generalized problem solving procedures that may be applied to a range of problems with very little modification \cite{Droste2006}.

% more detail - use info if avaiable
Domain specific knowledge refers to making use of known relationships between solution representations and the objective cost function. Generally speaking, the less domain specific information incorporated into a technique, the more flexible the technique, although the less efficient it will be for a given problem. For example, `random search' is the most general black box approach and is also the most flexible requiring only the generation of random solutions for a given problem, but its worst case behavior is worse than enumerating an entire search domain. As such, the more information available about a problem, the more that should be exploited by a technique in order to efficiently determine a solution for the problem, heuristically or otherwise. Black box methods are those methods suitable for those problems where little information from the problem domain is available to be used by a problem solving approach.  

% 
% No Free Lunch - based on copy from my thesis
% 
\subsection{No Free Lunch}
\label{subsec:nfl}
% intro
The \emph{No Free Lunch Theorem} of search and optimization by Wolpert and Macready proposes that all black box optimization algorithms are the same for searching for the extremum of a cost function when averaged over all possible functions \cite{Wolpert1997, Wolpert1995}. The theorem has caused a lot of pessimism and misunderstanding, particularly in related to the evaluation and comparison of computational intelligence algorithms.

% overview
The implication of the theorem is that searching for the `best' general-purpose black box optimization algorithm is theoretically impossible, as no such procedure exists. The theory applies to stochastic and deterministic optimization algorithms, and to algorithms that learn and adjust their search strategy over time. It is invariant to the performance measure used as well as the representation selected. Perhaps the catalyst for cynicism related to algorithm benchmarking is a comment accompanying the proof suggesting that: ``\ldots \emph{comparisons reporting the performance of a particular algorithm with a particular parameter setting on a few sample problems are of limited utility}'' \cite{Wolpert1997}.

% more
The theorem is an important contribution to computer science, although its implications are theoretical. The original paper was produced at a time when grandiose generalizations were being made as to algorithm, representation, or configuration superiority. The practical impact of the theory is to \emph{bound claims of applicability} for optimization algorithms. Wolpert and Macready encouraged effort be put into devising practical problem classes and the matching of suitable algorithms to problem classes. Further they compelled practitioners to exploit domain knowledge in optimization algorithm application, now an axiom in the field.

% 
% Randomness
% 
\subsection{Stochastic Optimization}
\label{subsec:stochastic}
% Stochastic
Stochastic optimization algorithms those that use randomness to elicit non-deterministic behaviors, contrasted to purely deterministic procedures. Algorithms from the fields of Computational Intelligence, Natural Computation, and Metaheuristics may be considered sub-fields of stochastic optimization. Algorithms that exploit randomness, are not random in behavior. Rather, they sample a problem space in a biased manner, focusing on areas of interest and neglecting less interesting areas \cite{Spall2003}. 
% mcmc
A class of techniques that focus on the stochastic sampling of a domain are called Markov Chain Monte Carlo (MCMC) that provide good average performance, quickly, and generally offer a low chance of the worst case performance. Such approaches are suited to problems with many coupled degrees of freedom, for example large high-dimensional spaces. MCMC approaches involve sampling from a target distribution function stochastically similar to Monte Carlo simulation methods) using a process that resembles a biased Markov chain.

% Monte Carlo
Monte Carlo methods are used for selecting a statistical sample to approximate a given target probability density function and are traditionally used in statistical physics. Samples are drawn sequentially and the process may include criteria for rejecting samples and biasing the sampling locations within high-dimensional spaces. 
% Markov Chian
Markov Chain processes provide a probabilistic model for state transitions or moves within a discrete domain called a walk or a chain of steps. A Markov system is only dependent on the position in the domain in order to probabilistically determine the next step in the walk. 

% mcmc
MCMC techniques combine these two approaches to solve integration and optimization problems in large dimensional spaces by generating samples while exploring the space using a Markov chain process rather than sequentially or independently \cite{Andrieu2003}. The step generation is configured to bias sampling in more important regions of the domain. Three examples of MCMC techniques include the Metropolis-Hastings algorithm, Simulated annealing for global optimization, and the Gibbs sampler which are commonly employed in the fields of physics, chemistry, statistics, and economics. 

% 
% Induction
% 
\subsection{Inductive Learning}
\label{subsec:induction}
% adaptation
Many unconventional optimization algorithms employ a process of iterative improvement of candidate solutions against an objective cost function. This process of adaptation is generally a method by which the process obtains characteristics that improve the system's (candidate solution) relative performance in an environment (cost function). This adaptive behavior is commonly achieved through a `selectionist process' of iterative generation, test, and modification. The use of non-deterministic processes mean that the sampling or learning is typically non-parametric, although biased, typically guided by past experience. 

% inductive learning
The method of acquiring information is called inductive learning or learning from example, where the approach uses the implicit assumption that specific examples are representative of the broader information content of the environment, specifically with regard to anticipated need. Many unconventional optimization approaches maintain a single candidate solution, a population of samples, or a compression thereof that provides both an instantaneous representation of all of information acquired by the process and the basis for future learning. 

% k-bandit
This method of simultaneously acquiring and improving information from the domain and the optimization of decision making (where to direct future effort) is called the $k$-armed bandit (two-armed and multi-armed bandit) problem from the field of statistical decision making or game theory \cite{Robbins1952} (for a contemporary treatment see \cite{Bergemann2006}). This formalism considers the capability of a strategy to allocate available resources proportional to the expected payoff the strategy is expected to receive. The classic example is the 2-armed bandit problem used by Goldberg to describe the behavior of the genetic algorithm \cite{Goldberg1989} where an agent learns about which slot machine provides more return by pulling the handle of each (sampling the domain) and basing which handle to pull proportional to the expected utility (experience with the past distribution of payoff). This formalism may also be used to understand the properties of inductive learning demonstrated by the adaptive behavior of most unconventional optimization algorithms.

% +/-
The limited use of prior knowledge from the domain (black box) coupled with the stochastic sampling process mean that adapted solutions created without without top-down insight or instruction can sometimes be interesting, innovative, and even competitive with decades of human expertise \cite{Koza2003}. The stochastic iterative process of generate and test can be computationally wasteful, potentially re-searching areas of the problem space already searched, and requiring many trials or samples in order to achieve a `good enough' solution.

% 
% Conclusions: summarise the document message and areas for future consideration
% 
\section{Conclusions}
\label{sec:conclusions}
% unconventional optimization algorithms
The selection of algorithms to be described in the Clever Algorithms are predominately unconventional optimization algorithms, meaning they are black box heuristics that use stochastic processes of iterative generate and test to adapt a candidate solution for a problem domain.
% overview
This report has clarified the relationship of the selected algorithms with the function optimization general class of problem, distinct to function approximation, instances of which can be phrased as optimization problems. This work has also clarified what is meant by the phrase `unconventional optimization algorithm' and pointed out the general philosophy of black-box algorithms, highlighted the broader field of stochastic optimization, the concerns of the no-free-lunch theorem, and suggested some explanations at how the approaches generally produce solutions.

% future
This report was not exhaustive in either describing the two general classes of problems, or with the introduction of unconventional optimization algorithms. 
% problem 
Sample problem instances may be provided to ground the introduction of the problem classes including both commonly cited benchmark instances, as well as real world examples.
% algorithms
The introduction of unconventional algorithms may further benefit from a more detailed explanation of subjects such as the state space paradigm, search, adaptation, and satisficing. Future efforts may consider an introduction into the classes of algorithm suited to different sub-classes of function optimization problems such as global and local, parallel, cooperative, hybrid and meta optimization.

% bibliography
\bibliographystyle{plain}
\bibliography{../bibtex}

\end{document}
% EOF
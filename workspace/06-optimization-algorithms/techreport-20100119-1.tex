% Unconventional Optimization Algorithms

% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2010 Jason Brownlee. All Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

\documentclass[a4paper, 11pt]{article}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{url}
\usepackage[pdftex,breaklinks=true,colorlinks=true,urlcolor=blue,linkcolor=blue,citecolor=blue,]{hyperref}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=25mm,bmargin=25mm,lmargin=25mm,rmargin=25mm}

% Dear template user: fill these in
\newcommand{\myreporttitle}{Unconventional Optimization Algorithms}
\newcommand{\myreportsubtitle}{An Overview}
\newcommand{\myreportauthor}{Jason Brownlee}
\newcommand{\myreportemail}{jasonb@CleverAlgorithms.com}
\newcommand{\myreportproject}{The Clever Algorithms Project\\\url{http://www.CleverAlgorithms.com}}
\newcommand{\myreportdate}{20100119}
\newcommand{\myreportversion}{1}
\newcommand{\myreportlicense}{\copyright\ Copyright 2010 Jason Brownlee. All Rights Reserved. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.}

% leave this alone, it's templated baby!
\title{{\myreporttitle}: {\myreportsubtitle}\footnote{\myreportlicense}}
\author{\myreportauthor\\{\myreportemail}\\\small\myreportproject}
\date{\today\\{\small{Technical Report: CA-TR-{\myreportdate}-\myreportversion}}}
\begin{document}
\maketitle

% write a summary sentence for each major section
\section*{Abstract} 
todo

\begin{description}
	\item[Keywords:] {\small\texttt{Clever, Algorithms, Unconventional, Optimization}}
\end{description} 

% summarise the document breakdown with cross references
\section{Introduction}
\label{sec:introduction}
% project
The Clever Algorithms project aims to describe a large number of Computational Intelligence and Natural Computation algorithms in a complete, consistent, and centralized manner \cite{Brownlee2010}.
% report
This report provides an overview of so-called `unconventional optimization algorithms'. These are stochastic global optimization algorithms drawn from the fields of Computational Intelligence, Biologically Inspired Computation, and Metaheurustics \cite{Brownlee2010c}.
% global optimization
Section~\ref{sec:global_optimization} provides an introduction to stochastic global optimization that introduces subjects such as black box methods, the `no free lunch theorem' of search and optimization, the importance of randomness, an and general strategy of inductive learning. 
% problems
Section~\ref{sec:problems} provides an overview of the general features that make computational problems difficult in the fields of Computational Intelligence and Metaheuristics and introduces two general classes of problem: function optimization and function approximation.
% conclusions
Finally, Section~\ref{sec:conclusions} relates the introduction of stochastic global optimization to the so-named `clever algorithms' from the Clever Algorithms project, and highlights some ares for future consideration.

% 
% Global Optimization
% 
\section{Global Optimization}
\label{sec:global_optimization}
what is global optimization all about?
there is also local optimization


% 
% Black Box Methods
% 
\subsection{Black Box Methods}
they make few assumptions about the problem domain
generalized problem solvers



% 
% No Free Lunch - based on copy from my thesis
% 
\subsection{No Free Lunch}
The `no free lunch theorem' of search is \ldots

Wolpert and Macready's \emph{No Free Lunch Theorem} of search and optimization has caused a lot of pessimism and misunderstanding, particularly in related to the evaluation and comparison of computational intelligence algorithms \cite{Wolpert1997, Wolpert1995}. In simplest terms, the theory indicates that when searching for an extremum of a cost function, \emph{all algorithms perform the same when averaged over all possible cost functions}. The implication is that the often perused general-purpose optimization algorithm is theoretically impossible. The theory applies to stochastic and deterministic optimization algorithms, and to algorithms that learn and adjust their search strategy over time. It is invariant to the performance measure used as well as the representation selected. Perhaps the catalyst for benchmarking cynicism is a comment accompanying the proof suggesting that: ``\ldots \emph{comparisons reporting the performance of a particular algorithm with a particular parameter setting on a few sample problems are of limited utility}'' \cite{Wolpert1997}.

% more
The theorem is an important contribution to computer science, although its implications are theoretical. The original paper was produced at a time when grandiose generalizations were being made as to algorithm, representation, or configuration superiority. The practical impact of the theory is to \emph{bound claims of applicability}. Wolpert and Macready encouraged effort be put into devising practical problem classes and the matching of suitable algorithms to problem classes. Further they compelled practitioners to exploit domain knowledge in optimization algorithm application, now an axiom in the field.


% 
% Randomness
% 
\section{Randomness}
The are stochastic processes.
stochastic global optimization

The interaction with the problem and the resultant adaptation have an inherent element of randomness that promotes approximation of acquired information, general robustness of the system to noise, and flexibility of the system to unexpected events. 

Monte Carlo methods
selecting a statistical sample to approximate a function
initially used in statistical physics
draw a set of samples from a target density function (high dimensional space)
can involve rejection sampling - not including samples into the set - rejecting them based on criteria
can bias sampling based on importance of variables

approximate a function with a set of samples. 
draw samples sequentially

Markov Chain Processes
about probabilistically performing state transitions in a discrete space domain
should not get trapped in cycles
all about state transition probabilities

MCMC
used to solve integration and optimization problems in large dimensional spaces
generate samples while exploring a high-dimensional space using a Markov chain process - configured so that the chain spends more time in the most important regions of the space - biased sampling
physics, statistics, economics, decision analysis
algorithms: Metropolis-Hastings algorithms, Simulated annealing for global optimization, the Gibbs sampler

samples are not drawn sequentially, they are drawn in an order determined by a Markov chain process

great overview of algorithms \cite{Andrieu2003}


% stochastic 
The acquired information is generally \emph{approximate}, and is done so using a \emph{stochastic method}. The general method is called Monte Carlo in which randomness is exploited to provide good average performance, quickly, and with a low chance of the worst case performance. Such approaches are suited to problems with many coupled degrees of freedom, for example large high-dimensional spaces. The selection method by which induction occurs may be modeled as a series of parallel random walks that exploit gradients in the underlying cost surface (directly, without derivatives), and as such is known as a Markov Chain Monte Carlo (MCMC) method \cite{Andrieu2003}. Generally, MCMC approaches involve sampling from a target distribution function using a process that resembles a Markov Chain. This highlights that the robustness of the approach extends to the induction process itself with regard to an improving approximation in the face of potentially incomplete, incorrect and inconsistent sampled data.


% 
% Induction
% 
\subsection{Adaptive Induction}
The typically learn by doing (trial and error)
generate, guess, revise

Information is acquired and generalized from discrete and specific examples provided by the problem.

% generally
These algorithms are \emph{adaptive} which is interpreted as their general capability of obtaining characteristics that improve the systems relative performance in an environment. This adaptive behavior is achieved through a \emph{selectionist process} of iterative selection and descent with modification. The discrete cell-based architecture is inherently \emph{parallel} allowing for concurrent selection processes, and is \emph{robust} providing redundancy of information and flexibility in terms of resource allocation. 

% inductive learning
The method of acquiring information is called \emph{inductive learning} (learning from example), where the approach uses the implicit assumption that specific examples are representative of the broader information content of the environment, specifically with regard to anticipated need. Generally, cellular approaches maintain a population of samples that provide both a representation for acquired information, and the basis for further induction.

% k-bandit
This method of simultaneously improving information and optimizing decisions is called the $k$-armed bandit (two-armed and multi-armed bandit) problem from the field of statistical decision making \cite{Robbins1952} (for a contemporary treatment see \cite{Bergemann2006}). This class of problem has had a long tradition of as a formalism for considering genetic algorithms and niching variants with regard to the adaptive processes capability of the `automatic' allocation of resources proportional to expected payoff \cite{Goldberg1989}.




% 
%  Problems - based on copy from my thesis
% 
\section{Problems}
\label{sec:problems}
% properties of problems - from that book


% classes
Two problem formalisms that embody many of the most difficult problems faced by Artificial and Computational Intelligence are introduced: Function Optimization in Section~\ref{subsec:function_optimization} and Function Approximation in Section~\ref{subsec:function_approximation}. Each formalism is described in terms of its general properties, a formalism, and a set of specialized sub-problems. These problem classes provide a tangible framing if algorithmic techniques drawn from the fields of Computational Intelligence, Natural Computing, and Metaheuristics.

% 
%  Function Optimization - based on copy from my thesis
%
\subsection{Function Optimization}
\label{subsec:function_optimization}
Real-world optimization problems and generalizations thereof can be drawn from most fields of science, engineering, and information technology (for a sample see \cite{Ali1997, Toern1999}). Importantly, optimization problems have had a long tradition in the fields of Artificial Intelligence and Computational Intelligence in motivating basic research into new problem solving techniques, and for investigating and verifying systemic behavior against benchmark problem instances.

%
% Problem Definition
%
\subsubsection{Problem Description}
% definition
Optimization (in the mathematical sense), is defined as the search for a combination of parameters commonly referred to as \emph{decision variables} ($x = \left\{x_1, x_2, x_3, \ldots x_n\right\}$) which minimize or maximize some ordinal quantity ($c$) (typically a scalar  called a score or cost) assigned by an \emph{objective function} or \emph{cost function} ($f$), under a set of constraints ($g = \left\{g_1, g_2, g_3, \ldots g_n\right\}$). For example, a general minimization case would be as follows: $f(x\prime) \leq f(x), \forall x_i \in x$. Constraints may provide boundaries on decision variables (for example in a real-value hypercube $\Re^n$), or may generally define regions of feasibility and in-feasibility in the decision variable space or cost space. In applied mathematics the field may be referred to as \emph{Mathematical Programming}. More generally the field may be referred to as \emph{Global} or \emph{Function Optimization} given the focus on the objective function (for more general information on optimization, see \cite{Horst2000}). 

%
% Sub-fields
%
\subsubsection{Sub-Fields of Study}
% general taxonomy
The study of optimization is comprised of many specialized sub-fields, generally based on an overlapping taxonomy that focuses on the principle concerns in the general formalism. 
% general fields
For example, with regard to the decision variables, one may consider univariate and multivariate optimization problems. The type of decision variables promotes the specialities for continuous, discrete, and permutations of variables. Dependencies between decision variables under a cost function defines the fields of Linear Programming, Quadratic Programming, and Nonlinear Programming. A large class of optimization problems can be reduced to discrete sets, which are considered in the field of Combinatorial Optimization, to which many theoretical properties are known, most importantly that many interesting and relevant problems cannot be solved by an approach with polynomial time complexity (so-called NP-complete, for example see \cite{Papadimitriou1998}).

% need for more complex models
The topography of the response surface for the decision variables under the cost function may be convex, which is an important class of functions to which many important theoretical findings have been made, not limited to the fact that location of the local optimal configuration also means the global optimal configuration of decisional variables has been located \cite{Boyd2004}. Many interesting and real-world optimization problems produce cost surfaces that are non-convex or so called multi-modal\footnote{Taken from statistics referring to the centers of mass in distributions, although in optimization it refers to `regions of interest' in the search space, in particular valleys in minimization, and peaks in maximization cost surfaces.} (rather than uni-modal) suggesting that there are multiple peaks and valleys. Further, many real-world optimization problems with continuous decision variables cannot be differentiated given their complexity or limited information availability meaning that derivative-based gradient decent methods that are well understood are not applicable, requiring the use of so-called `direct search' (sample or pattern-based) methods \cite{Lewis2000}. Further, real-world objective function evaluation may be noisy, non-continuous, and dynamic, and the constraints of real-world problem solving may require a viable or approximate solution in limited time or resources, motivating the need for inductive model-generation based approaches.


% 
%  Function Approximation - based on copy from my thesis
%
\subsection{Function Approximation}
\label{subsec:function_approximation}
% relation to ai and ci
The phrasing of real-world problems in the Function Approximation formalism are among the most computationally difficult considered in the broader field of Artificial Intelligence for reasons including: incomplete information, high-dimensionality, noise in the sample observations, and non-linearities in the target function.
% this section
This section considers the \emph{Function Approximation Formalism} and related specialization's as a general motivating problem for demonstrating the suitability of the applicability of clonal selection algorithms from across the hierarchical framework.

%
% Problem Definition
%
\subsubsection{Problem Description}
% definition
Function Approximation is an \emph{inductive problem} of finding a function ($f$) that approximates a target function ($g$), where typically the approximated function is selected based on a sample of observations ($x$, also referred to as the \emph{training set}) taken from the unknown target function.
% ML
In machine learning, the function approximation formalism is used to describe general problem types commonly referred to as \emph{pattern recognition}, such as classification, clustering, and curve fitting (so-called decision or discrimination function). Specifically, such general problem types are described in terms of approximating an unknown Probability Density Function (PDF), which underlies the relationships in the problem space, and represented to some degree in the sample data. This function approximation perspective of such problems is commonly referred to as \emph{statistical machine learning} and/or density estimation \cite{Fukunaga1990, Bishop1995}.


%
% Sub-Fields of Study
%
\subsubsection{Sub-Fields of Study}
% really hard
The function approximation formalism can be used to phrase some of the hardest problems faced by Computer Science, and Artificial Intelligence in particular such as natural language processing and computer vision. 
% general process
The general process focuses on (1) the collection and preparation of the observations from the target function, (2) the selection and/or preparation of a model of the target function, and (3) the application and ongoing refinement of the prepared model. 
% important problem types 
Some important problem-based sub-fields include: \emph{Feature Selection} where a feature is considered an aggregation of attributes, where only those features that have meaning in the context of the target function are necessary to the modeling process \cite{Kudo2000, Guyon2003}, \emph{Classification} where observations are inherently organized into labelled groups (classes) and a supervised process models an underlying discrimination function to classify unobserved samples, \emph{Clustering} where observations may be organized into inherent groups based on common features although the groups are unlabeled requiring a process to model an underlying discrimination function without corrective feedback, and \emph{Curve or Surface Fitting} where a model is prepared that provides a `best-fit' (or regression) for a set of observations that may be used for \emph{interpolation} over known observations and \emph{extrapolation} for observations outside what has been observed.

% optimisation
The field of Function Optimization is related to Function Approximation, as many-sub-problems of Function Approximation may be defined as optimization problems. As such many of the inductive modeling paradigms are differentiated based on the representation used and/or the optimization process used to minimize error or maximize effectiveness on a given approximation problem. 
% problems
The difficulty of Function Approximation problems centre around (1) the nature of the unknown relationships between attributes and features, (2) the number (dimensionality) of of attributes and features, and (3) general concerns of noise in such relationships and the dynamic availability of samples from the target function.
% other problems
Additional difficulties include the incorporation of prior knowledge (such as imbalance in samples, incomplete information and the variable reliability of data), and problems of invariant features (such as transformation, translation, rotation, scaling and skewing of features).



% 
% Conclusions: summarise the document message and areas for future consideration
% 
\section{Conclusions}
\label{sec:conclusions}
relationship to clever algorithms, what aspects do we care about?
what is an unconventional optimization algorithm?
model building compared to search - func approximation compared to func optimization

what other areas could be look at?
state space, search, adaptation, satisificing



% bibliography
\bibliographystyle{plain}
\bibliography{../bibtex}

\end{document}
% EOF
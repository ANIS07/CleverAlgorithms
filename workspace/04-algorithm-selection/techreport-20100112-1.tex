% The Clever Algorithms Project: Algorithm Selection

% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2010 Jason Brownlee. All Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

\documentclass[a4paper, 11pt]{article}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{url}
\usepackage[pdftex,breaklinks=true,colorlinks=true,urlcolor=blue,linkcolor=blue,citecolor=blue,]{hyperref}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=25mm,bmargin=25mm,lmargin=25mm,rmargin=25mm}

% Dear template user: fill these in
\newcommand{\myreporttitle}{The Clever Algorithms Project}
\newcommand{\myreportsubtitle}{Algorithm Selection}
\newcommand{\myreportauthor}{Jason Brownlee}
\newcommand{\myreportemail}{jasonb@CleverAlgorithms.com}
\newcommand{\myreportproject}{The Clever Algorithms Project\\\url{http://www.CleverAlgorithms.com}}
\newcommand{\myreportdate}{20100112}
\newcommand{\myreportversion}{1}
\newcommand{\myreportlicense}{\copyright\ Copyright 2010 Jason Brownlee. All Rights Reserved. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.}

% leave this alone, it's templated baby!
\title{{\myreporttitle}: {\myreportsubtitle}\footnote{\myreportlicense}}
\author{\myreportauthor\\{\myreportemail}\\\small\myreportproject}
\date{\today\\{\small{Technical Report: CA-TR-{\myreportdate}-\myreportversion}}}
\begin{document}
\maketitle

% write a summary sentence for each major section
\section*{Abstract} 
This is the abstract. Consider writing a one sentence summary of each major section in the report.

\begin{description}
	\item[Keywords:] {\small\texttt{Clever, Algorithms, Algorithm, Selection, Methodology}}
\end{description} 

% summarise the document breakdown with cross references
\section{Introduction}
\label{sec:introduction}
% project
The Clever Algorithms project aims to describe a large number of algorithms from the field of Artificial Intelligence in a complete, consistent, and centralized way to improve the accessibility of the methods \cite{Brownlee2010}. 
% report
This report focuses on the methodology for selecting algorithms that appear in the project and provides a preliminary suggested listing of algorithms to describe. 
% breakdown
Section~\ref{sec:methodology} describes a data-driven methodology for organizing, evaluating, and selecting algorithms. Section~\ref{sec:results} summarizes the raw results of applying the methodology in terms of the ranked algorithms. Section~\ref{sec:analysis} analyzes the presented results and comments on areas for improvement in the methodology. Section~\ref{sec:selection} provides a preliminary listing of algorithms selected to be described in the Clever Algorithms project. The listing is not final, rather it is presented as a first draft to be refined over the lifetime of the project. Section~\ref{sec:conclusions} reviews the findings of the process, and highlights some areas for future consideration.

% 
% Methodology
% 
\section{Methodology}
\label{sec:methodology}
This section describes the methodology for the selection of algorithms for inclusion in the Clever Algorithms project. This methodology and its results are based on a post on the blog `Never Read Passively' by Jason Brownlee (this author) on August 2nd 2009 entitled ``What is a good optimization algorithm? A data-driven method for algorithm selection''\footnote{Online: \url{http://www.neverreadpassively.com/2009/08/what-is-good-optimization-algorithm.html}}. The method presented in this previous work was based on the question: \emph{Is it possible to select a diverse, interesting, and useful set of inspired algorithms using a simple data driven method?}. The methodology presented in this section is updated to include more sources used for algorithm comparison and use a weighted sum when calculating an algorithms ranking. The application of this methodology was updated to use an automated script, and the listing of algorithms for evaluation was updated and refined. The methodology is presented in terms of the three core tasks in the process: algorithm list, algorithm ranking, and algorithm selection.

% 
% Algorithm List
% 
\subsection{Algorithm List}
The first task involve the preparation of a large listing of candidate algorithms. The algorithms may be drawn from the an array of fields under or related to the fields of Biologically Inspired Computation and Computational Intelligence, such as: Metaheuristics, Hyperheuristics, Natural Computation, Biomementics, Swarm Intelligence, Collective Intelligence, and Evolutionary Computation.

The sources for algorithms names should be diverse and may include books, articles, papers, magazines, websites, and software. The specification of the algorithm in the list is important. Algorithm name standardization is an important aspect of the methodology. The algorithm should be listed in their canonical (most common) name, normalized, without acronyms (wherever reasonably possible), and in their full unabbreviated form

Each algorithm should be assigned a kingdom for taxonomic reasons. The kingdom is used to group algorithms which defines the scope of competition that the algorithms must survive to be included in the project. Kingdoms may be superficial names (such as the taxonomic names the algorithms may be assigned in book chapters general observation and intuition), such as: evolutionary, immunological, swarm, physical, probabilistic, and stochastic.

% 
% Algorithm Rankings
% 
\subsection{Algorithm Rankings}
Each algorithm in the prepared listing must be evaluated, assigned a scoring, and ranked to allow selection decisions to be made. A data-driven popularity-based approach is proposed for algorithm evaluation. Each algorithm name is submitted to an array of different domain specific search engines and the total approximated number of results reported by the search services are taken as measures. The submission of the algorithm name is standardized such that it is surrounded by quotes to ensure that the search is specific and the algorithm name is converted to lower case. 

Some example search domains to which algorithm names may be submitted include:
\begin{itemize}
	\item \emph{Google Web Search}: Search of webpage on the internet index by Google.
	\item \emph{Google Book Search}: Search of books index by Google.
	\item \emph{Google Scholar Search}: Search of the academic publications and patents index by Google.
	\item \emph{Springer Article Search}: Search of the articles and papers published by Springer.
	\item \emph{Scirus Article Search}: Search of the articles and papers index by Scirus.
\end{itemize}

The collected measures are representative of how often an algorithm name appears in a particular search domain, and inferred to represent the popularity to which a given algorithm is written about and studied. This data-driven algorithm evaluation strategy may be simply stated as \emph{An algorithm or method is as good its name, as useful and interesting as it is abundant}, or more specifically, an algorithm that is used (written about) is an algorithm that is useful (worth knowing about). 

The collected measures are then combined to produce a scoring for a given algorithm name. The combination may be a weighted sum of the measures, where different weighting factors may be used to increase the influence of a particular search domain. For example an algorithms's occurrence in published books may have more importance than an algorithms occurrence on webpages. 

Finally, the calculated algorithms scores are used to compare algorithms. Algorithm comparisons may be direct, or may be scoped, such as by using an algorithms allocated taxonomic kingdom.

% 
% Algorithm Selection
% 
\subsection{Algorithm Selection}
The selection of the algorithms that are considered in the project is as important, if not more important, than the descriptions of the algorithms themselves. The particular mixture of algorithms must be include popular techniques that readers are expected to lookup, although the pool must be diverse enough to be interesting and promote discovery.

cannot use rank alone

order by rank, filter for interestingness
organize by field or sub-field or some commonality

list in order of increasing complexity, a logical narrative perhaps

% 
% Results
% 
\section{Results}
\label{sec:results}
This section summarizes the results of assessing algorithms for inclusion in the Clever Algorithms project.

i focused on `unconventional optimization algorithms', leaving out so-called model building approaches from statistical machine learning such as artificial neural networks, fuzzy logic, kernels, etc 

not out of the project for good, just out for now - perhaps a two volume study? algorithms and models

Top overall?
Top for each field?
list all results? good for completeness 

% 
% Analysis
% 
\section{Analysis}
\label{sec:analysis}
This section analyses the results of the assessed algorithms for inclusion in the Clever Algorithms project.

common base names boosting some algorithms, like the ga


\subsection{Problems with Algorithm Names}
not all algorithms are equal, some are more heuristics than true procedures
not all have well defined names
algorithms are renamed
self references boost numbers
time of publication, new algorithms get lower ranks, older get higher

\subsection{Problems with Algorithm Names}
measures from different domains are absolute, not relative
arbitrary weighting factors

some data points that would be nice but were not used
some nice data points would include: objective efficiency, efficacy, quality of research, and maybe even scope of innovation

\section{Selected Algorithms}
\label{sec:selection}
This section provides a listing of 50 algorithms selected for description in the Clever Algorithms Project. The presentation of this list of algorithms is partitioned into sub-domains that are expected to represent Chapters in the final work. Each algorithm is listed with at least one primary or seminal source to verify the existence of the approach.

not final, just a first best guess based on available information
composition must be large, diverse, interesting. 
selection based on a filtered version of the ranked listings

\subsection{Stochastic Algorithms}

\subsection{Evolutionary Algorithms}

\subsection{Swarm Algorithms}

\subsection{Immune Algorithms}

\subsection{Probabilistic Algorithms}

\subsection{Physical Algorithms}


% summarise the document message and areas for future consideration
\section{Conclusions}
\label{sec:conclusions}
This is the conclusion. Consider summarizing the message of the document once again, and highlighting areas for future consideration.

The project now has preliminary algorithm chapters and sections.
this does not have to be maintained, it is just a first attempt at outlining the scope of the project

future books on models, not just algorithms
use this methodology for selecting other discrete topics for research. popularity based selection method

% bibliography
\bibliographystyle{plain}
\bibliography{../bibtex}

\end{document}
% EOF
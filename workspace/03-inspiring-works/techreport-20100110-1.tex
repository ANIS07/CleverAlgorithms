% The Clever Algorithms Project: Inspiring Works

% The Clever Algorithms Project: http://www.CleverAlgorithms.com
% (c) Copyright 2010 Jason Brownlee. All Rights Reserved. 
% This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.

\documentclass[a4paper, 11pt]{article}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{url}
\usepackage[pdftex,breaklinks=true,colorlinks=true,urlcolor=blue,linkcolor=blue,citecolor=blue,]{hyperref}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=25mm,bmargin=25mm,lmargin=25mm,rmargin=25mm}

% Dear template user: fill these in
\newcommand{\myreporttitle}{The Clever Algorithms Project}
\newcommand{\myreportsubtitle}{Inspiring Works}
\newcommand{\myreportauthor}{Jason Brownlee}
\newcommand{\myreportemail}{jasonb@CleverAlgorithms.com}
\newcommand{\myreportproject}{The Clever Algorithms Project\\\url{http://www.CleverAlgorithms.com}}
\newcommand{\myreportdate}{20100110}
\newcommand{\myreportversion}{1}
\newcommand{\myreportlicense}{\copyright\ Copyright 2010 Jason Brownlee. All Rights Reserved. This work is licensed under a Creative Commons Attribution-Noncommercial-Share Alike 2.5 Australia License.}

% leave this alone, it's templated baby!
\title{{\myreporttitle}: {\myreportsubtitle}\footnote{\myreportlicense}}
\author{\myreportauthor\\{\myreportemail}\\\small\myreportproject}
\date{\today\\{\small{Technical Report: CA-TR-{\myreportdate}-\myreportversion}}}
\begin{document}
\maketitle

% write a summary sentence for each major section
\section*{Abstract} 
todo

\begin{description}
	\item[Keywords:] {\small\texttt{Clever, Algorithms, Inspiration, Works, Motivation}}
\end{description} 

% summarise the document breakdown with cross references
\section{Introduction}
\label{sec:introduction}
% message
The Clever Algorithms project seeks to describe a large number of algorithms from the fields of Computational Intelligence and Biologically Inspired Computation in a complete, consistent, and centralized manner \cite{Brownlee2010}. The project was not devised in isolation, it was inspired and influenced by a diverse collection of books (Section~\ref{sec:books}) and software (Section~\ref{sec:software}). This technical report provides an overview of the works that influenced the inception and development of the Clever Algorithms project and distills and synthesizes the specific features from all the inspirations into a set of principles and actions to help guide the project (Section~\ref{sec:findings}).

\section{Books}
\label{sec:books}
This section summarizes specific books that influenced the Clever Algorithms project.

% 
% Society of Mind
% 
\subsection{The Society of Mind}
The Society of Mind by Marvin Minsky \cite{Minsky1988} proposes a society of automata or processes referred to as agents in a theory that seeks to explain how the mind works. The theory is presented as a series of approximately 270 one page thought experiments organized into 30 chapters (and an appendix) each representing a specific feature or artifact of the mind. 

Minsky also proposed the book as a society of many small ideas, that collectively propose the theory. Through-out the book, Minsky acknowledges comments and influence from students that helped refine specific elements, suggesting that the content for the book was developed over an extended period and presented for feedback. Each page explores a concept with a theory experiment or explanation that is used as a building block on one or more other pages. As a result there are many cross-connections between the one page essays. In the prolog section, Minsky highlights the cross connections between the topics a necessary artifact of his construction, like the cross connections in the mind itself. In the postscript and acknowledgements section, Minsky mentions that he tried to re-write the content `several times' but found that a more traditional narrative could not accommodate all of the ideas effectively. 

% what i like
Minsky's book was influential in the fields of Artificial Intelligence and Psychology. It is an exemplar for the content development model proposed for the Clever Algorithms project. In addition to content development, the end product in the book itself is an example of how such a content development model may be usefully stitched together and collectively presented to an audience as a series of discrete (separable), semi-independent (some cross references) structure of essays. 

% 
%  Evolutionary Computation
% 
\subsection{Evolutionary Computation}
\label{subsec:ec}
The Handbook of Evolutionary Computation \cite{Baeck1997} is a compendium (presented as a folder) of articles written by experts in the field of Evolutionary Computation generally about their specialty sub-fields. The objective of the handbook was to present complete, clear, and accessible information throughly describing state-of-the-art evolutionary computation research and application in a comprehensive style. The handbook presents 8 parts that cover a range of topics (introduction, fundamental concepts, computational models, hybrid approaches, implementations, applications, case studies, and research), each of which is partitioned into chapters that presents a series of independent articles (title, content, and references) authored by various different experts.

This project was later updated resulting in the release of two books:

\begin{itemize}
	\item Evolutionary Computation 1: Basic Algorithms and Operations \cite{Baeck2000}
	\item Evolutionary Computation 2: Advanced Algorithms and Operations \cite{Baeck2000a}
\end{itemize} 

The two volumes present similar material as the handbook although updated, and under a broader structure that presents increased detail. Volume one presents a series of six parts that cover major topics on evolutionary algorithms (why evolutionary computation, standard algorithms, representations, selection, and search) with 34 chapters, each chapter presenting anywhere between one and ten articles by specialists in the field. The second volume presents a similar structure (parts, chapters, articles) and focuses on more advanced topics in the field (fitness evaluation, constraint handling techniques, population structures, advanced techniques, and implementation). The articles are like short journal pieces with the same manner as the handbook with independent authorship and isolated structure (title, content, and references).

% what i like
The handbook and the updated book volumes are seminal references for practitioners and researches in the field of evolutionary computation. The content in a given article is suitable to gain a basic understanding of an approach or operation, there dearth of articles means that all major subfields and niches in the area of research are covered, and the compactness of each article means that a number can be consumed in a given sitting. 
% random access
A reader can skim across topics by flicking through the table of contents and dive into a specific sub field in a random access manner - both properties of good reference texts. The articles are independent, with few (if any) explicit cross connections, although any required prior knowledge is located in one or more other articles in the collection.

% same field
The handbook and volumes cover a field and a number of algorithms and related topics that are expected to be covered in the clever algorithms project. The handbook and volumes do present algorithms with pseudo code, but they are presented as areas of research, and are presented differently between the algorithms. The Clever Algorithms project is different in that it focuses only on the presentation of algorithms rather than focusing on the myriad of sub-fields, and all algorithms will be presented using the same structure. The Evolutionary Computation books are complementary to the Clever Algorithms project, providing a specific and more detailed reference (although at least ten years out of date at the time of writing) to accompany the presentation of most of the evolutionary algorithms in the project.

% 
%  Handbook of Exact String Matching Algorithms
% 
\subsection{Handbook of Exact String Matching Algorithms}
\label{subsec:strings}
% what is the book all about
The Handbook of Exact String Matching Algorithms by Christian Charras and Thierry Lecroq \cite{Charras2004} is a technical book that presents 34 string matching algorithms. The book starts with a single chapter providing some context for the field of text processing and the importance of string matching, some conventions, then proceeds to present algorithms, one per chapter. The description of each algorithm is systematic, including the following sections:

\begin{itemize}
	\item \emph{Title}: The name of the algorithm used as the chapter title.
	\item \emph{Main features}: A short bullet-point listing of the computational complexity (efficiency) and data structures used in the algorithm.
	\item \emph{Description}: A terse textual description of the distinctiveness of the algorithm, sometimes with bullet pointed features, diagrams, and mathematical equations. 
	\item \emph{The C code}: A concise listing of algorithm's source code in the C programming language, sometimes with a brief textual description.
	\item \emph{The example}: Commonly a listing of the matching procedure on a specific problem instance, depicting the algorithms behavior graphically for each iteration until the example problem is solved.
	\item \emph{References}: A bullet-point listing of references suitable for understanding the presented algorithm.
\end{itemize}

% general
Both PDF and Postscript versions of the book is available for free from Thierry Lecroq's (one of the authors) website \url{http://www-igm.univ-mlv.fr/~lecroq/livres.html}, and the book can be purchased traditionally, such as from Amazon. It is unclear whether the published version of the text resembles the PDF version reviewed. The website for the author also shows four other books on string matching, highlighting the authors interest and dedication to the field. Again, it is unknown whether the other published volumes adopt a similar book structure and algorithm presentation methodology.

% what I liked 
The book is an excellent model for the clever algorithms project. It is a text that focuses on the presentation of a large corpus of algorithms (I had no idea there were 34 ways to test-match strings), in a complete (varied presentation forms) and consistent (fixed structure) way. THe inclusion of a `main features' element in the description is something that may be considered in the clever algorithms standardized algorithm description template \cite{Brownlee2010a}. The focused domain (string matching) allows for a consistent graphical motif to be used for algorithm descriptions that both effective and meaningful within the domain. Generally, the algorithm descriptions are terse, providing sufficient information to understand the approach without drowning the reader, whilst providing a listing of seminal references for those interested to acquire a deeper understanding. Finally, a version of the book is available for free on the author's website (although, under no obvious copyright license) and the book can be purchased traditionally, allowing both interested amateurs (like myself) and the experts to locate and make use of it.

% 
%  Cory Doctorow Novels
% 
\subsection{Cory Doctorow Novels}
\label{subsec:doctorow}
Cory Doctorow, among other professions, is a science fiction writer and proponent of the Creative Commons organization. Doctorow publishes his novels traditionally and releases his novels both under permissive licenses, allowing the works to be re-worked by fans. I have read two of Doctorow's novels, specifically: 

\begin{itemize}
	\item \emph{Down and Out in the Magic Kingdom} \cite{Doctorow2003}
	\item \emph{Someone Comes to Town, Someone Leaves Town} \cite{Doctorow2006}
\end{itemize}

Down and Out in the Magic Kingdom has a dedicated webpage \url{http://craphound.com/down} that provides a free copy of the novel in multiple formats under the Creative Commons Attribution-Noncommercial-No Derivative Works 1.0 Generic License. Someone Comes to Town, Someone Leaves Town also has a dedicated webpage \url{http://craphound.com/someone} that provides free downloads of the book released under the Creative Commons Attribution-Noncommercial-No Derivative Works 2.0 License. Generally, the reader can reproduce the work (different file formats, languages, publications, re-arrangements of the text, and even audiobooks), although cannot modify it (without permission), make money from it, and must provide the appropriate attribution. These books are popular because they are both great stories, although the adopted license has allowed a community to spring up around the respective books. Each books webpage provides a blog that tracks updates to the unconventional publication and distribution of the works, encouraging the community to go even further. As of writing, the download page for Down and Out' shows 36 different versions of the book and Someone Comes to Town' shows 31 versions, presumably mostly prepared by fans.

% what i like
Doctorow's works, specifically these two books provide great examples of what may be achieved by distributing the book traditionally and releasing its content under a permissive license (assuming an excellent base product). These cases highlight active community discussion and encouragement of derivative works are desirable properties for reaching a wider audience (an authors failure is not being read). Science fiction is a domain that may engender passion and fans, and so ambitions of community may be less transferable to other domains. The tools of facilitation appear to include not only a permissive license such as Creative Commons, hosting free copies of the book on a dedicated website, the encouragement of the reader-base to generate derivative works, and the promotion of created derivative works on the books webpage.

% 
% Clonal Selection as an Inspiration for Adaptive and Distributed Information Processing
% 
\subsection{Clonal Selection as an Inspiration for Adaptive and Distributed Information Processing}
\label{subsec:dissertation}
The PhD dissertation in the field of Artificial Immune Systems by Jason Brownlee \cite{Brownlee2008}, the current author. The thesis presents a series of adaptive information processing models inspired by specific structures and functions of the acquired immune system. The content for the thesis was developed initially as a series of nearly 50 discrete, semi-independent technical reports over a period of approximately six-months, available online from \url{http://www.it.swin.edu.au/personal/jbrownlee}. A total of 11 algorithms clonal selection algorithms were described in a semi-structured format motivated by the following descriptive elements:

\begin{itemize}
	\item \emph{Inspiration}: A summary of the motivating structure and/or functions of the acquired immune system for the proposed algorithm or system.
	\item \emph{Strategy}: An abstraction of the inspiring system as a description of the computational processes, data structure, and architecture (if appropriate).
	\item \emph{Empirical Assessment}: One or a series of structured experiments (aim, method (problem, algorithm, experiment), results, analysis, conclusions) with the algorithm applied to a problem instance in order to demonstrate and empirically confirm the presence of expected systemic information processing properties. The description of empirical experiments was structured, including the following named elements:
	\begin{itemize}
		\item \emph{Aim}: The objective of the experiment.
		\item \emph{Method}: A declaration of the problem instance, algorithm procedure in pseudo code, and experimental procedure.
		\item \emph{Results}: A presented summary of the results
		\item \emph{Analysis}: A textual analysis of the presented results and their potential impact.
		\item \emph{Conclusions}: A textual summary of the findings of the experiment and their relationship to the stated objectives.
	\end{itemize}
\end{itemize}

% what i do/don't like
The algorithm description was somewhat structured, although without explicitly named description elements to encourage presentation consistency, although the motivating nature of the descriptions was formative for the clever algorithms project. A fixed and named structure was adopted for the description of empirical experiments, although generally the presentation of each algorithm was too verbose, compared to the concise descriptions discussed in Section~\ref{subsec:strings}.
% discrete
The content development methodology adopted for the Clever Algorithms project is patterned after the method used in the development of this thesis. A series of discrete, semi-independent (cross-referenced) technical reports was prepared on topics expected to be in and/or related to the topics presented in the thesis. The reports were prepared first and then reproduced with modification in the thesis in a patch work fashion, with gaps being filled as required. 

% change
This process will be adopted with some changes in the preparation of the book deliverable for the Clever Algorithms project. A series of technical reports will be prepared for topics expected to be in or related to the content of the front and back matter of the book, although one report will be written for each algorithm that appears in the book. Additionally, the content of the book (and potentially other deliverables such as a website) are proposed to be developed in parallel with the technical reports in a series of discrete milestones. 
 

% 
% A Field Programmers Guide to Genetic Programming
% 
\subsection{A Field Programmers Guide to Genetic Programming}
A Field Programmers Guide to Genetic Programming is a book by Riccardo Poli, William Langdon, and Nicholas McPhee \cite{Poli2008}. The book is about the field of Genetic Programming, a sub-field of Evolutionary Computation. The book is self-published using the LuLu service (\url{http://www.lulu.com}) providing both a dead tree version for just over \$22USD with delivery (at the time of writing) and an eBook version for free released under the Creative Commons Attribution-Noncommercial-No Derivative Works 2.0 UK: England and Wales License.

% web
The book has a dedicated website on the form of a blog \url{http://www.gp-field-guide.org.uk}, as well as a user group for discussing the topics and pointing highlighting errata in the content. The books website links to the two published versions of the book, as well as the books presence on other online retailers such as Amazon. The blog discusses topics such as errata, positive mentions and reviews as well as tracking sales volumes and site visits. The book topic and it's free availability has made it popular in google listings (when searching for `genetic programming') as well as online technical communities. 

% what i like
The book is in a field related to the Clever Algorithms project, although focuses on one technique - the genetic programing algorithms - and its variants, extensions, and applications in great detail. The self-publishing service LuLu handles both the on-demand publishing of the book as a paperback and a hosting facility for the ebook, providing tracking of sales and downloads to the authors for both concerns. The free status, quality content, and seniority of the authors in the field have strongly contributed to the success (tracked downloads) of the book. The self-published status suggest the intent of the project was readership, although the popularity of the book may also suggest that some reasonable revenue may have also been generated (split three ways though). 

% 
% Pro Git
% 
\subsection{Pro Git}
Pro Git is a book published by Scott Chacon \cite{Chacon2009} about the distributed version control system git. The book has a dedicated website \url{http://progit.org} that provides the content of the book for free in HTML released under a permissive Creative Commons Attribution-Non Commercial-Share Alike 3.0 license. Unlike the license used to distributed Doctorow's books in Section~\ref{subsec:doctorow}, this license allows the derivative works to me modified although they cannot be commercial and must include appropriate attribution. The book website also promotes the dead-tree version, and provide a blog with topics related to the broader uptake of the book as well as translations of the books contents to other languages prepared by readers.
 
% version control
The book also provides the source code for the presented examples as a publicly readable project on the Github website \url{http://github.com/progit/book-examples}. Interestingly, the HTML version (specifically markdown that is rendered as HTML) of the book is also made available as a publicly readable project on Github \url{http://github.com/progit/progit}. It appears that both of these projects were created after the release of the book and are intended to be used to track errata. The book project has been forked and translated, the results of which have been pulled back (included) in the original project allowing moderated public contributions to the project. Viewing the commit log shows that contributions to the project frequent and that development (translations) are active at the time of writing.

% what I like
The book is not about algorithms and does not contain algorithm descriptions, although it is a model for developing the content for a book in a publicly accessible version control system and for web-based dissemination. Github is a social version control platform that encourages collaboration. The usage of Github to track errata for the examples source code and the book content is an excellent idea that can be exploited further. 
%  don't like
The book project on github does provide a README providing a terse context for the effort, although it does not (at the time of writing) explain the directory structure of the project, how users may contribute, or how or why the project came into existence. Github is a platform for collaboration and informing users how they may collaborate on a project that clearly has community interest (493 project followers and 133 forks at the time of writing) is expected to be a priority. 

It is likely that the book content was not released publicly under a permissive license until after the publication of the dead-tree version because of contractual constraints of the publisher. No such constraints are imposed on the Clever Algorithms project. As such, the content can be developed in a publicly readable repository allowing ad hoc contributions from any user who wishes to contribute the project. Such contributions are not required to complete the project, and are not generally expected given the limited size of the target audience (even compared to git users), although the opportunity for such contributions is facilitated by the project.


% 
% Global Optimization Algorithms: Theory and Applications
% 
\subsection{Global Optimization Algorithms - Theory and Applications}
Global Optimization Algorithms - Theory and Applications by Thomas Weise \cite{Weise2007} about the broader field of optimization techniques in the field of Artificial Intelligence. The book is release for free as a PDF on Weise's website \url{http://www.it-weise.de} under the GNU Free Documentation License, Version 1.2. 

The book provides a large preface that describes the work as a the outcome of an extended project by Weise investigating the field, and that the book is not currently complete with incomplete sections marked with a `TODO' statement in read text, sometimes in a large sized font. The book was started in 2006, is up to it's second revision (as of writing), although is periodically updated and made available online. Differentiation between the many versions of the book is made through the issue number, and many reference styles for the book are provided. The book also credits `a large number of people' as providing corrections and contributions to the book over its lifetime.

The book is through and enormous, totaling 820 pages at the time of writing (Version: 2009-06-26). It covers a large number of topics, such as specific Computational Intelligence optimization algorithms and algorithm families, each of which is allocated a chapter for discussion. Algorithm descriptions are detailed including a narrative of background, inspiration, equations, pseudo code, application areas, books, and configuration. Aspects of a given technique may also be described at great length including variations, proofs, and applications.

% What i like
The book covers the broader field directly related to the Clever Algorithms project and includes many of the techniques expected to be described by the project. Additionally, the book is the product of a side project by a practitioner and expert in the field, very much like the Clever Algorithms project, although Weise appears a lot more distinguished. 
% don't like
The book is detailed and may provide an excellent reference text, although it is too detailed compared to the vision of for the clever algorithms book deliverable. Additionally, the book project is in its fourth year of likely discontinuous development and its volume may be an artifact of project scope creep. 

% like
The project involves the periodic self-publishing of an incomplete work. The process has resulted in a lot of useful feedback according to the author that contribute to the quality of the work, and this is an advantage of an agile or iterative content development methodology (release early, release often). Reading a self-published book in an incomplete state is expected to damage the reputation of the quality of the project as it is a discomfort to the reader. It is proposed that an incomplete book is different to an incomplete piece of software, the latter is functional whereas the former is not. This problem may be addressed through the proposed technical report content development methodology for the Clever Algorithms project (early and complete sub-releases), and through a commitment to only releasing completed versions of the book deliverable.  

% 
% O'Reilly Cookbooks
% 
\subsection{O'Reilly Cookbooks}
% what is it all about 
O'Reilly Cookbooks are a series of book published by O'Reilly Media that present recipes or quick fixes to common and specific programming problems. A typical book is partitioned into chapters for major topics and each chapter is partitioned into specific recipes. The recipes are presented in a consistent format (problem, solution, discussion, see also), where the solution is most commonly a sequence of actions or snippet of code that can be directly used (in a target programming language, in an executable form, and an exemplar and best practices solution to the presented problem). 

O'Reilly has a website dedicated to the series \url{http://oreilly.com/store/series/cookbooks.csp} that provides an effective description, as follows: ``\emph{Each cookbook contains hundreds of programming recipes presented in a special Problem/Solution/Discussion format, and includes hundreds of scripts, programs, and command sequences you can use to solve specific problems}'' The source code from each cookbook is provided on O'Reilly website and can be downloaded and copied directly into user applications, presumably released under a permissive license. The recipe structure taken from the O'Reilly website is as follows:

\begin{itemize}
	\item \emph{Problem}: Each problem is clearly stated, specific, and practical.
	\item \emph{Solution}: The solution is easy to understand and implement.
	\item \emph{Discussion}: The discussion clarifies and explains the context of the Problem and Solution.
	\item \emph{See Also}: Directs you to additional information related to the topic.
\end{itemize}

The O'Reilly Cookbooks webpage lists approximately 50 books in the series (at the time of writing), each on a specific subject such as a programming language, environment, or development platform. Perhaps the most famous book in the series is the Perl Cookbook by Tom Christiansen and Nathan Torkington \cite{Christiansen2003} that may have started the series, the source code solutions of which have subsequently been ported to a number of other programming languages and released under the GNU Free Documentation License on a website dedicated to the maintenance of the examples \url{http://pleac.sourceforge.net}.

% what i like
Although not about algorithms specifically, the cookbook format from O'Reilly is an excellent model for the presentation of content in the Clever Algorithms project. Essentially, each book is a compendium of discrete, independent, terse problem-solution pairs with executable programming code presented as the solutions.
The intent of the Clever Algorithms project is to produce a reference text with the same general properties, although on a more complex subject matter, the details of which are dispersed across an elusive corpus of papers, articles, books, websites, and source code.

% ec
The cookbook format is very similar to the article approach used in the Evolutionary Computation books discussed in Section~\ref{subsec:ec}, although with a fixed presentation structure and more independence between the sections. A reader may search the table of contents (or the content electronically) and locate a solution to the general class to their specific problem. Alternatively, a reader may browse the text, and randomly access knowledge on an array of specific best practice programming idioms.
% re-create
This experience may be recreated in the Clever Algorithms project for artificial intelligence practitioners seeking general algorithmic solutions suited to difficult problems and a corpus of such solutions that may be browsed for inspiration.

% 
%  Software
% 
\section{Software}
\label{sec:software}
This section summarizes specific software that influenced the Clever Algorithms project.

% 
% WEKA
% 
\subsection{Waikato Environment for Knowledge Analysis}
The Waikato Environment for Knowledge Analysis (WEKA) is a machine learning workbench for exploring and experimenting with machine learning algorithms and data mining processes \cite{Hall2009}. It is an open source software platform developed by the University of Waikato written in Java and released under the GNU General Public License (GPL). The project is used in university level machine learning and data mining course, is a platform for scientific enterprise, has a dedicated website for the project \url{http://www.cs.waikato.ac.nz/~ml/weka} and at least one book written by the main contributors \cite{Witten2000} (now in at a second edition).

The description from the WEKA webpage is as follows: ``\emph{Weka is a collection of machine learning algorithms for data mining tasks. The algorithms can either be applied directly to a dataset or called from your own Java code. Weka contains tools for data pre-processing, classification, regression, clustering, association rules, and visualization. It is also well-suited for developing new machine learning schemes.}''

% what i like
The WEKA platform is host to a large number of standardized algorithm implementations for general classes of problems such as regression, classification, feature selection and clustering. The platform is concerned with the fields of data mining and machine learning that may have some overlap with the Clever Algorithms project. The number of algorithms is always increasing as third party developers implement algorithms and researches implement and investigate their own approaches. I have been interested in the platform for a long time and have contributed to the effort by writing a series of algorithms for the platform \url{http://wekaclassalgos.sourceforge.net}. 

The software specifies programatic contracts (interfaces, base types, abstract methods) that must be implemented for an algorithm to be included with the platform, enforcing standardization. This contract also includes referencing primary sources, parameterization documentation, and default algorithm configuration. These three pieces of information are invaluable to a practitioner in understanding where an algorithm came from, how to configure it, and a starting point for blind application (bad practice, but a typical use case). 
% i don't like
What the algorithms are missing are more detailed descriptions. This is a point that that the associated book works to address, although it departs from the structured standardized presentation style used in the software.

% model for community
The large number of algorithms, and the high quality implementations has attracted a lot of attention resulting in it being considered a premiere platform for research in applied machine learning and data mining with many papers and articles referencing the software and the project. This supposition highlights that a positive feedback loop may be created for such a practical effort to the point where it becomes a de-facto standard in the field. 

% 
% OAT
% 
\subsection{Optimization Algorithm Toolkit}
The Optimization Algorithm Toolkit (OAT) is a software platform created by Jason Brownlee (this author) in Java for exploring and experimenting with optimization algorithms from the fields of Computational Intelligence and Biologically Inspired Computation \cite{Brownlee2007}. It was developed between 2006 and 2008, was extended for use in Brownlee's dissertation work (Section~\ref{subsec:dissertation}), and is released as open source under the GNU Lesser General Public License (LGPL) version 3. The project has a dedicated website \url{http://optalgtoolkit.sourceforge.net} that describes the general use cases, the target audience, and provides support information.

A description of the project from the projects website is as follows: ``\emph{The Optimization Algorithm Toolkit (OAT) is a workbench and toolkit for developing, evaluating, experimenting, and playing with classical and state-of-the-art optimization algorithms on standard benchmark problem domains. The software includes reference algorithm implementations, graphing, visualizations, and much more.}''

The project was inspired by the WEKA platform, although targeted optimization algorithms, providing a large number of problem and algorithm instances for a number domains (such as continuous function optimization, binary function optimization, traveling salesman problem, and graph coloring). Algorithms are drawn from many fields of study such as Evolutionary Computation, Swarm Intelligence, Ant Colony Optimization, and Stochastic Optimization. Like the WEKA project, the OAT library enforces algorithm implementation standardization through the use of programming artifacts (interfaces, base classes, and abstract methods).

% what i like
The OAT provides a large number of algorithms that are expected to appear in the Clever Algorithms project. In fact, the Clever Algorithms project is an effort to re-create and improved version of the OAT effort to be more accessible. OAT was broadly targeted to scientists, developers, and amateurs, although was only really usable by programmers that were also domain experts and likely research scientists. Additionally, a failure of the OAT project was that it did not provide sufficient support or documentation for the implemented algorithms. 

% 
% Watchmaker
% 
\subsection{Watchmaker}

good quality library, used
the guy is everywhere, wherever the techniques are being discussed his is participating
highlighting is project as needed, results in exposure - active participation results in exposure by default


% 
% Findings
% 
% summarise the document message and areas for future consideration
\section{Findings}
\label{sec:findings}
% what did we cover?

% what can we use from all this?
The following describe a set of properties distilled from the inspiring works:

\subsection{Regarding Content}

\begin{itemize}
	\item \emph{Discrete Content Development}: semi-independence of content for information to promote discrete consumption and grazing
	\item \emph{Deliverable Milestones}: produce milestones of the primary deliverables in parallel with the discrete content development tech reports. finish the tech reports, finish the book, two-way feedback, iterations. release version of the book, use the milestone and date as the version number, like the tech reports. continuously usable/accessible/able to be referenced 
	\item \emph{Compact}: minimal content, enough to be useful to target audience, pointers to more, address information overload 
	\item \emph{Structure}: consistent algorithm structure, already adopted but reinforced
	\item \emph{Volume}: lots of algorithms, be a landmark or atlas, shock people at the number of algorithms
	\item \emph{Publicly Developed}: attribution is recorded for posterity, progress is tracked, interest is tracked, content is backed up, contributions can be made form anywhere, and by any one (although moderated before added to the main project)
	\item \emph{Algorithm Focus}: it is all about the techniques, front and back matter should be minimal
	\item \emph{Clear and Fixed Scope} a set number of algorithms, early specification of how many and which ones (first milestone), can be refined, but need an early commitment to avoid scope creep
	\item \emph{Independence} few if any explicit cross connections, assuming reasonable prior knowledge, dip in and out of algorithms
	\item \emph{Algorithm Usage} what do all the parameters mean, how are they configured, what is a default configuration
\end{itemize}

\subsection{Regarding Product}

\begin{itemize}
	\item \emph{Permissive License}: let people consume/reproduce the way they want, state license and copyright in all work product and source material, choose a license and explain it
	\item \emph{Marketing}: dedicated webpage, promotion of derisive works, promote book on publishes site, encourage reviews on publisher site, promote signed copies, promote sales figures, google rankings, web page visits, citations, etc
	\item \emph{Disseminate}: grass roots marketing, push tech reports around the web, google index, scribd, etc
	\item \emph{Pricing}: cheapest possible, promote reading, not profit
	\item \emph{Publishing}: self publish, ebook online for free, track downloads of ebook 
	\item \emph{Referencing}: Provide a way to reference the work product (tech reports), milestones, and the project itself, allow people to reference everything with a link and a citation
	\item \emph{Complete Book} only release complete versions of the book, not versions in incomplete states.
	\item \emph{Foster Collaboration}: for the project in version control, explain what it is, when it was created, why it was created and how users can collaborate. be social
\end{itemize}


% bibliography
\bibliographystyle{plain}
\bibliography{../bibtex}

\end{document}
% EOF
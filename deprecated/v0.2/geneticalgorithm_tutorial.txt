Genetic Algorithm Tutorial
Copyright (C) 2008 Jason Brownlee

Change History
2008/12/03  JB  Created

Introduction 
This tutorial covers how to implement a genetic algorithm that operates on candidate solutions with binary genomes to solve the OneMax problem.

Problem
The problem instance is called OneMax which scores binary strings based on the number of 1's in the string. It is a popular objective function for demonstrating the Genetic Algorithm as it does not required the binary string to be mapped to another domain, allowing the direct evaluation. 

def count_ones(bitstring)
  bitstring.inject(0) {|sum, x| sum + ((x=='1') ? 1 : 0)}
end

The problem specific mapping and evaluation of solutions by an oracle objective function is computationally the most time consuming aspect of the genetic algorithm.

The OneMax function demonstrates an important principle for the genetic algorithm, and that is relationship of an oracle objective function used for the atomic assessment of candidate solutions. The objective function (or fitness function) is a black box to the algorithm, providing numerical scorings of candidate solutions that only have meaning in the context of other assessed candidate solutions to which the algorithm has been exposed.

In the case of the OneMax problem, the algorithm will receive the same scoring for two very different strings (for example 111000 and 100101). This highlights the generality of the algorithm, where the algorithm solves through a process of induction using only fitness information. For example, if 111000 becomes 111001, the algorithm conserves the new string with the explicit knowledge that the improvement in fitness was caused by making a '0' become a '1'. 

Solution
The solution is represented as a binary string genome, in this case an array of characters where each position in the array can have the value of '0' or '1'. Each BinarySolution has a fitness value associated with it, evaluated and assigned by the objective function of the OneMaxProblem.

New solutions are seeded with random bit strings and are used at the beginning of an algorithm run. 

def initialize_random(length)
  @genome = Array.new(length)
  @genome.fill {|index| Random.next_bool ? "1" : "0"}
end

The typical case during the run involves the creation of new candidate solutions (offspring) from candidate solutions already selected and evaluated (parents). This recombination process involves copying sequences of bits from each parent, where the copying process (or transcription) of each value occurs with some probability of error.

def initialize_recombination(parent1, parent2)
  # ensure first and last positions are never selected (always cross)
  pos = Random.next_int(parent1.genome.length - 2) + 1
  # create a new genome
  @genome = Array.new(parent1.genome.length)
  # recombine the genomes with copy errors
  @genome.fill do |index|
    if index < pos
      @genome[index] = transcribe parent1.genome[index]
    else
      @genome[index] = transcribe parent2.genome[index]
    end
  end
end

def transcribe(value)
  if Random.next_float < heuristic_mutation_rate(@genome.length)
    return ((value == "1") ? "0" : "1" )
  end
  return value
end

Importantly, the solutions are specific to the problem, in this case binary strings with floating point fitness scorings. The genetic algorithm logic relevant to manipulating solutions (the crossover and mutation procedures) are encapsulated within the solution class and specialized for the character-based binary strings.

Algorithm
The algorithm is implemented as a generic (not problem specific) and reusable system that manages a population of candidate solutions over a set of generations in the context of a provided problem definition. The problem provides interfaces for the algorithm to acquire new and recombined candidate solutions, solution evaluation and solution comparisons - encapsulating notions of relative improvement (maximization or minimization). 

As such, the algorithm initializes some internal state at the beginning of each evolve request and executes generations, each of which creates a new population for the existing old population of candidate solutions. The algorithm keeps track of the best solution found to date (as defined by the problem) and stops executing generations after a stop condition is triggered. In this case a set number of generations or an optimal solution is located as defined by the problem (in this case the optimal solution is equal to the number of bits in the problem).

def evolve(problem)
  # store problem
  @problem = problem
  # prepare the population and state
  initialize_population
  # evolve until stop condition is triggered
  while not should_stop? do
    @population = evolve_population population
  end
end

def evolve_population(population)
  # evaluate
  population.each do |solution| 
    @problem.cost solution 
    @best_solution = @problem.choose_better @best_solution, solution
  end
  # select
  selected = population.collect {|solution| tournament_select solution, population}
  # recombine and mutate
  new_population = Array.new(population.length)
  population.each_with_index do |solution, index|
    # probabilistic crossover or promotion
    if Random.next_float < heuristic_crossover_rate        
      if index.modulo(2)==0
        new_population[index] = @problem.new_solution_recombine(solution, population[index+1])
      else
        new_population[index] = @problem.new_solution_recombine(solution, population[index-1])
      end
    else
      new_population[index] = solution
    end
  end
  # one more generation has completed
  @generation += 1
  puts "#{@generation}, best: #{@best_solution}"    
  return new_population
end

The evolve_population function does all the hard work, first evaluating the population, selecting the breeding set using tournament-based fitness proportionate-selection, and creating the new population from the selected set. Recombination occurs probabilistically with a high probability. When recombination is not used, the candidate solution is directly promoted to the new population.

The fitness tournament is a simple and efficient implementation of selection that involves a set number of bouts (fights) for each position in the breeding set. The bouts a decided based on the candidate solutions assigned fitness, the relative comparisons of which are assessed using the problem definition.

def tournament_select(base, population)
  bouts = 1
  while bouts <= heuristic_selection_num_bouts do
    pos = Random.next_int(population.length)
    candidate = population[pos]
    base = @problem.choose_better(base, candidate)
    bouts += 1
  end
  return base
end

Summary
The Genetic Algorithm has a number of parameters which influence the greediness and randomness of the algorithm. Given the number of probabilistic decisions made during each iteration of the algorithm, the same inputs to the algorithm can provide an array of varied output results, such as the best solution found. As such, it is important that the system is executed a number of times for any given configuration. This will provide a more meaningful understanding of the algorithms capability for a configuration on a problem.
